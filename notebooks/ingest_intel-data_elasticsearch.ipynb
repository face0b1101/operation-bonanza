{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Setting up Elasticsearch\n",
    "\n",
    "The process we'll follow is:\n",
    "\n",
    "1. Create an Elasticsearch client\n",
    "2. Check if the required ingest pipeline exists, and create it if not\n",
    "3. Check if the index with proper mappings exists, and create it if not\n",
    "4. Load the intelligence data into the index\n",
    "\n",
    "This ensures we don't overwrite existing settings if the index is already properly configured - and, importantly, don't ingest duplicate data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Notebook stages\n",
    "\n",
    "1. **Connect to Elasticsearch**: Create a client using cloud credentials.\n",
    "2. **Prepare ML + ingest**: Import and deploy the NER model `conll03_english_ner_ingest` (Hugging Face: `elastic/distilbert-base-uncased-finetuned-conll03-english`), then ensure the ingest pipeline and index exist.\n",
    "3. **Ingest intelligence reports**: Load NDJSON files from `../data/intel-reports` into the index using the bulk API with progress reporting and basic error logging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from collections.abc import Iterator\n",
    "\n",
    "from decouple import config\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import UTC, datetime\n",
    "\n",
    "from elasticsearch import Elasticsearch, NotFoundError\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "# Load environment variables from .env file\n",
    "ES_CLOUD_ID = config(\"ES_CLOUD_ID\", default=\"\")\n",
    "ES_API_KEY = config(\"ES_API_KEY\", default=\"\")\n",
    "\n",
    "# define Elasticsearch config files\n",
    "es_index_name = \"data.service-intelligence.reports-force1\"\n",
    "es_index_settings_file = (\n",
    "    \"../elasticsearch/indices/demo-investigation-intel.reports.json\"\n",
    ")\n",
    "\n",
    "es_ingest_pipeline_name = \"investigation-intel.reports-pipeline\"\n",
    "es_ingest_pipeline_file = (\n",
    "    \"../elasticsearch/pipelines/investigation-intel.reports-pipeline.json\"\n",
    ")\n",
    "\n",
    "# NER model configuration (Hugging Face: elastic/distilbert-base-uncased-finetuned-conll03-english)\n",
    "ner_model_id = \"conll03_english_ner_ingest\"\n",
    "ner_hf_model_id = \"elastic/distilbert-base-uncased-finetuned-conll03-english\"\n",
    "\n",
    "# define data directory\n",
    "data_dir = \"../data/intel-reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elasticsearch client\n",
    "if not ES_CLOUD_ID or not ES_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"ES_CLOUD_ID and ES_API_KEY must be set in the environment variables.\"\n",
    "    )\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    cloud_id=ES_CLOUD_ID,\n",
    "    api_key=ES_API_KEY,\n",
    ")\n",
    "\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ingest_pipeline(\n",
    "    es_client: Elasticsearch, pipeline_file: str, pipeline_name: str\n",
    ") -> bool:\n",
    "    \"\"\"Create the ingest pipeline if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        es_client: Elasticsearch client\n",
    "        pipeline_file: Path to the pipeline definition file\n",
    "        pipeline_name: Name of the pipeline to create\n",
    "\n",
    "    Returns:\n",
    "        bool: True if pipeline was created, False if it already existed\n",
    "    \"\"\"\n",
    "    # Check if pipeline exists\n",
    "    try:\n",
    "        es_client.ingest.get_pipeline(id=pipeline_name)\n",
    "        print(f\"Pipeline '{pipeline_name}' already exists\")\n",
    "        return False\n",
    "\n",
    "    except Exception:\n",
    "        print(f\"Pipeline '{pipeline_name}' not found, creating it...\")\n",
    "\n",
    "        # Load pipeline definition from file\n",
    "        with open(pipeline_file) as file:\n",
    "            pipeline_definition = json.load(file)\n",
    "\n",
    "        # Create the pipeline\n",
    "        es_client.ingest.put_pipeline(id=pipeline_name, body=pipeline_definition)\n",
    "\n",
    "        print(f\"Pipeline '{pipeline_name}' created successfully\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(es_client: Elasticsearch, index_file: str, index_name: str):\n",
    "    \"\"\"Create the index if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        es_client: Elasticsearch client\n",
    "        index_file: Path to the index definition file\n",
    "        index_name: Name of the index to create\n",
    "\n",
    "    Returns:\n",
    "        bool: True if index was created, False if it already existed\n",
    "    \"\"\"\n",
    "    # Check if index exists and store the result\n",
    "    if es_client.indices.exists(index=index_name).body:\n",
    "        print(f\"Index '{index_name}' already exists\")\n",
    "    else:\n",
    "        # If index does not exist, create it\n",
    "        print(f\"Index '{index_name}' not found, creating it with proper mappings...\")\n",
    "\n",
    "        # Load index definition from file\n",
    "        with open(index_file) as file:\n",
    "            index_definition = json.load(file)\n",
    "\n",
    "        # Create the index with settings and mappings\n",
    "        if es_client.indices.create(index=index_name, body=index_definition).body:\n",
    "            print(f\"Index '{index_name}' created successfully\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to create index '{index_name}'\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_ndjson_generator(filepath: str) -> Iterator[dict]:\n",
    "    \"\"\"Yield one JSON object at a time from an NDJSON file.\"\"\"\n",
    "    with open(filepath, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping malformed JSON in {filepath}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_elasticsearch(\n",
    "    es_client: Elasticsearch,\n",
    "    es_index_name: str,\n",
    "    data_dir: str,\n",
    "    chunk_size: int = 500,\n",
    "    request_timeout: int = 120,\n",
    "):\n",
    "    \"\"\"Read NDJSON files and load them into Elasticsearch using the bulk API.\n",
    "\n",
    "    This mirrors the more robust ingestion pattern from ``ingest_data_elasticsearch.ipynb``\n",
    "    and avoids per-document timeouts by batching requests and setting an explicit\n",
    "    HTTP request timeout.\n",
    "\n",
    "    Args:\n",
    "        es_client: Elasticsearch client\n",
    "        es_index_name: The index name to load data into\n",
    "        data_dir: Directory containing ndjson files\n",
    "        chunk_size: Number of documents per bulk request\n",
    "        request_timeout: Timeout in seconds for each bulk request\n",
    "    \"\"\"\n",
    "    all_files = glob.glob(f\"{data_dir}/*.ndjson\")\n",
    "\n",
    "    if not all_files:\n",
    "        print(f\"No .ndjson files found in '{data_dir}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_files)} files to process...\")\n",
    "    total_successes = 0\n",
    "\n",
    "    # Create a client with timeout options\n",
    "    client_with_timeout = es_client.options(request_timeout=request_timeout)\n",
    "\n",
    "    def generate_es_actions(filepath: str, index_name: str, pbar: tqdm):\n",
    "        \"\"\"Yield Elasticsearch bulk actions from an NDJSON file and update a progress bar.\"\"\"\n",
    "        for doc in reddit_ndjson_generator(filepath):\n",
    "            pbar.update(1)\n",
    "            yield {\n",
    "                \"_op_type\": \"index\",\n",
    "                \"_index\": index_name,\n",
    "                \"_source\": doc,\n",
    "            }\n",
    "\n",
    "    # show progress for file processing\n",
    "    for filepath in tqdm(all_files, desc=\"Processing files\"):\n",
    "        filename = os.path.basename(filepath)\n",
    "\n",
    "        # Pre-count lines so we can show doc-level progress per file\n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            total_lines = sum(1 for _ in f)\n",
    "\n",
    "        try:\n",
    "            with tqdm(\n",
    "                total=total_lines,\n",
    "                desc=f\"Uploading {filename}\",\n",
    "                unit=\"doc\",\n",
    "            ) as pbar:\n",
    "                action_generator = generate_es_actions(filepath, es_index_name, pbar)\n",
    "\n",
    "                success_count, errors = bulk(\n",
    "                    client=client_with_timeout,\n",
    "                    actions=action_generator,\n",
    "                    chunk_size=chunk_size,\n",
    "                    raise_on_error=False,\n",
    "                )\n",
    "            total_successes += success_count\n",
    "\n",
    "            if errors:\n",
    "                tqdm.write(\n",
    "                    f\"⚠️  Finished {filename}: Loaded {success_count} documents with {len(errors)} errors.\"\n",
    "                )\n",
    "            else:\n",
    "                tqdm.write(\n",
    "                    f\"✅ Finished {filename}: Loaded {success_count} documents successfully.\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"❌ A critical error occurred with {filename}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Ingestion Complete ---\")\n",
    "    print(f\"Total documents loaded successfully from all files: {total_successes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_ner_model(\n",
    "    es_client: Elasticsearch,\n",
    "    model_id: str = ner_model_id,\n",
    "    hf_model_id: str = ner_hf_model_id,\n",
    ") -> dict:\n",
    "    \"\"\"Ensure the CONLL03 NER model exists and is deployed for ingest pipelines.\n",
    "\n",
    "    The model weights are imported from the Hugging Face model\n",
    "    ``elastic/distilbert-base-uncased-finetuned-conll03-english``\n",
    "    (see `https://huggingface.co/elastic/distilbert-base-uncased-finetuned-conll03-english`).\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"model_exists\": False,\n",
    "        \"deployment_status\": \"not_checked\",\n",
    "    }\n",
    "\n",
    "    # Step 1: Check if the trained model exists, importing from Hugging Face if needed.\n",
    "    try:\n",
    "        print(f\"Checking for trained model: {model_id}\")\n",
    "        models_response = es_client.ml.get_trained_models(model_id=model_id)\n",
    "\n",
    "        if models_response.body.get(\"count\", 0) > 0:\n",
    "            result[\"model_exists\"] = True\n",
    "            print(f\"✓ Model '{model_id}' found in cluster\")\n",
    "        else:\n",
    "            # The API responded but returned no models; treat as not found.\n",
    "            raise NotFoundError(\"no_trained_models\", \"Model not found in cluster\")\n",
    "\n",
    "    except NotFoundError:\n",
    "        # The client raises NotFoundError when the model id is unknown. In this case\n",
    "        # we pivot to importing the model from Hugging Face using Eland.\n",
    "        print(\n",
    "            f\"Model '{model_id}' not found in cluster. Attempting import from Hugging Face \"\n",
    "            f\"as '{hf_model_id}'...\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            from pathlib import Path\n",
    "\n",
    "            from eland.ml.pytorch import PyTorchModel\n",
    "            from eland.ml.pytorch.transformers import TransformerModel\n",
    "        except ImportError as import_err:  # pragma: no cover - environment-specific\n",
    "            raise ImportError(\n",
    "                \"The 'eland' package is required to import models from Hugging Face. \"\n",
    "                \"Install it in this environment, for example with 'uv add eland' or \"\n",
    "                \"'pip install eland', and re-run this cell.\"\n",
    "            ) from import_err\n",
    "\n",
    "        try:\n",
    "            # Download and export the Hugging Face model via Eland.\n",
    "            transformer_model = TransformerModel(\n",
    "                model_id=hf_model_id,\n",
    "                task_type=\"ner\",\n",
    "            )\n",
    "\n",
    "            models_dir = Path(\"models\")\n",
    "            models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            model_path, config, vocab_path = transformer_model.save(models_dir)\n",
    "\n",
    "            # Import the TorchScript model into Elasticsearch as a trained model.\n",
    "            ptm = PyTorchModel(es_client, model_id)\n",
    "            ptm.import_model(\n",
    "                model_path=model_path,\n",
    "                config_path=None,\n",
    "                vocab_path=vocab_path,\n",
    "                config=config,\n",
    "            )\n",
    "\n",
    "            result[\"model_exists\"] = True\n",
    "            print(\n",
    "                f\"✓ Hugging Face model '{hf_model_id}' imported into Elasticsearch \"\n",
    "                f\"as trained model '{model_id}'\"\n",
    "            )\n",
    "\n",
    "        except Exception as import_error:\n",
    "            raise ValueError(\n",
    "                f\"Failed to import Hugging Face model '{hf_model_id}' into \"\n",
    "                f\"Elasticsearch as '{model_id}': {import_error}\"\n",
    "            ) from import_error\n",
    "\n",
    "    except Exception:\n",
    "        # Bubble up unexpected errors during model existence/import checks.\n",
    "        raise\n",
    "\n",
    "    # Step 2: Start or update model deployment\n",
    "    try:\n",
    "        print(f\"Starting/updating deployment for model: {model_id}\")\n",
    "\n",
    "        try:\n",
    "            deployment_stats = es_client.ml.get_trained_models_stats(\n",
    "                model_id=model_id\n",
    "            ).body\n",
    "            current_deployment = None\n",
    "\n",
    "            if deployment_stats.get(\"count\", 0) > 0:\n",
    "                trained_models = deployment_stats.get(\"trained_model_stats\", [])\n",
    "                if trained_models and \"deployment_stats\" in trained_models[0]:\n",
    "                    current_deployment = trained_models[0][\"deployment_stats\"]\n",
    "\n",
    "            # If already deployed, check current state\n",
    "            if current_deployment:\n",
    "                current_state = current_deployment.get(\"state\", \"\")\n",
    "                print(f\"  Current deployment state: {current_state}\")\n",
    "\n",
    "                if current_state == \"started\":\n",
    "                    result[\"deployment_status\"] = \"already_started\"\n",
    "                    print(\"  Model deployment already active\")\n",
    "                else:\n",
    "                    es_client.ml.start_trained_model_deployment(\n",
    "                        model_id=model_id,\n",
    "                        wait_for=\"started\",\n",
    "                    )\n",
    "                    result[\"deployment_status\"] = \"started\"\n",
    "                    print(\"✓ Model deployment started\")\n",
    "            else:\n",
    "                es_client.ml.start_trained_model_deployment(\n",
    "                    model_id=model_id,\n",
    "                    wait_for=\"started\",\n",
    "                )\n",
    "                result[\"deployment_status\"] = \"started\"\n",
    "                print(\"✓ Model deployment started\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if \"resource_already_exists_exception\" in str(e):\n",
    "                result[\"deployment_status\"] = \"already_started\"\n",
    "                print(\"  Model deployment already exists and is active\")\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error starting model deployment: {e}\")\n",
    "        result[\"deployment_status\"] = f\"error: {e}\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the NER model is available and deployed for ingest\n",
    "ner_result = deploy_ner_model(es_client=es_client)\n",
    "\n",
    "print(\"\\n--- NER Model Setup ---\")\n",
    "print(f\"Model exists: {ner_result['model_exists']}\")\n",
    "print(f\"Deployment status: {ner_result['deployment_status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline and index if they don't exist\n",
    "create_ingest_pipeline(\n",
    "    es_client=es_client,\n",
    "    pipeline_file=es_ingest_pipeline_file,\n",
    "    pipeline_name=es_ingest_pipeline_name,\n",
    ")\n",
    "\n",
    "create_index(\n",
    "    es_client=es_client, index_file=es_index_settings_file, index_name=es_index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the function to load Reddit data to Elasticsearch\n",
    "load_data_to_elasticsearch(\n",
    "    es_client=es_client,\n",
    "    es_index_name=es_index_name,\n",
    "    data_dir=data_dir,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
